import os
import uuid
from pydantic import BaseModel
from llama_cpp import Llama
from docx import Document
import gradio as gr

# åŠ è½½ Qwen æ¨¡å‹
llm = Llama(
    model_path="models/Qwen3-0.6B-UD-Q4_K_XL.gguf",
    n_ctx=2048,
    n_threads=4,
    n_gpu_layers=0,
    verbose=False
)

# å®šä¹‰æ•°æ®æ¨¡å‹ç±»
class DocumentRequest(BaseModel):
    title: str
    context: str

def generate_text(prompt: str) -> str:
    """ç»Ÿä¸€çš„æ–‡æœ¬ç”Ÿæˆå‡½æ•°"""
    output = llm(
        prompt ,
        max_tokens=1024,
        temperature=0.4,
        stop=["<|endoftext|>"]
    )
    return output['choices'][0]['text'].strip()

#å‰ç«¯ï¼šGradio é¡µé¢
def gradio_analyze(file):
    file_id = str(uuid.uuid4())[:8]
    output_path = f"output/{file_id}_åˆ†ææŠ¥å‘Š.docx"
    doc = Document(file.name)
    context = "\n".join([para.text for para in doc.paragraphs])
    prompt = f"""ä½ æ˜¯ä¸€åæ–‡æ¡£åˆ†æå¸ˆï¼Œè¯·åˆ†æä»¥ä¸‹å†…å®¹ï¼š
1. è¯†åˆ«æ–‡æ¡£ç±»å‹å’Œæ ¸å¿ƒä¸»é¢˜
2. ç”¨ 150 å­—æ€»ç»“ä¸»è¦å†…å®¹\n\n{context}\n\nåˆ†ææŠ¥å‘Šï¼š"""
    output = llm( 
        prompt,
        max_tokens=1024,
        temperature=0.5,
        top_p=0.9,
        repeat_penalty=1.1, 
        stop=["<|endoftext|>"]
    )
    analysis = output['choices'][0]['text'].strip()
    result_doc = Document()
    result_doc.add_heading(f"æ–‡æ¡£åˆ†ææŠ¥å‘Š - {os.path.basename(file.name)}", 0)
    result_doc.add_paragraph(analysis)
    result_doc.save(output_path)
    
    return output_path

# åˆ›å»º Gradio ç•Œé¢
gradio_app = gr.Interface(
    fn=gradio_analyze,
    inputs=gr.File(label="ä¸Šä¼ æ–‡æ¡£ (.docx)", file_types=[".docx"]),
    outputs=gr.File(label="ä¸‹è½½åˆ†ææŠ¥å‘Š"),
    title="ğŸ“„ Autoch-alpha æ–‡æ¡£æ™ºèƒ½åˆ†æç³»ç»Ÿ--åŸºäºQwenå¤§æ¨¡å‹",
    description="ä¸Šä¼  Word æ–‡æ¡£ï¼ŒAI å°†è‡ªåŠ¨åˆ†æå†…å®¹å¹¶ç”Ÿæˆåˆ†ææŠ¥å‘Š",
    allow_flagging="never"
)

# å¯åŠ¨æœåŠ¡
if __name__ == "__main__":
    import webbrowser
    webbrowser.open("http://localhost:7860") # è‡ªåŠ¨æ‰“å¼€æµè§ˆå™¨ï¼ˆå¥½çƒ¦ä¸æè¿˜ä¸èƒ½è‡ªå·±è¹¦å‡ºæ¥ï¼‰
    gradio_app.launch()
